name: "Generate Video Ja"

on:
  repository_dispatch:
    types: [tts_dual_text_to_telegram]
  workflow_dispatch:
    inputs:
      summary:
        description: "Summary text (shown on video)"
        required: true

      storySlug:
        description: "Story slug"
        required: true
      storyId:
        description: "Story ID"
        required: true
      chapters:
        description: "Comma or newline separated chapter slugs (e.g. chuong1, chuong2, chuong3)"
        required: true
      content:
        description: "Full story content (will be split into N parts based on chapters count)"
        required: true

      background_tiktok_url:
        description: "TikTok background (Drive fileId or Drive URL)"
        required: true
      background_youtube_url:
        description: "YouTube background (Drive fileId or Drive URL)"
        required: true

      folder_name:
        description: "Drive subfolder name under GDRIVE_FOLDER_ID"
        required: true

      voice:
        description: "TTS voice"
        required: false
        default: "ja-JP-NanamiNeural"

      # Google Drive access token (no refresh in workflow)
      access_token:
        description: "Google Drive OAuth access token (Bearer)"
        required: true

      title:
        description: "Custom title (optional). If empty, auto-generate from date + summary_short"
        required: false
        default: ""

env:
  TZ: Asia/Tokyo

  # Pick values from repository_dispatch payload OR workflow_dispatch input
  ACCESS_TOKEN: ${{ github.event.client_payload.access_token || inputs.access_token }}
  SUMMARY: ${{ github.event.client_payload.summary || inputs.summary }}
  TITLE: ${{ github.event.client_payload.title || inputs.title }}

  STORY_SLUG: ${{ github.event.client_payload.storySlug || inputs.storySlug }}
  CHAPTERS: ${{ github.event.client_payload.chapters || inputs.chapters }}

  BG_TT: ${{ github.event.client_payload.background_tiktok_url || inputs.background_tiktok_url }}
  BG_YT: ${{ github.event.client_payload.background_youtube_url || inputs.background_youtube_url }}
  FOLDER_NAME: ${{ github.event.client_payload.folder_name || inputs.folder_name }}
  VOICE: ${{ github.event.client_payload.voice || inputs.voice || 'ja-JP-NanamiNeural' }}
  CONTENT: ${{ github.event.client_payload.content || inputs.content }}

jobs:
  prepare:
    name: Prepare inputs
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Validate inputs + write work files (safe)
        run: |
          set -euo pipefail
          mkdir -p work
          python3 - <<'PY'
          import os, re

          title = os.environ.get("TITLE") or ""
          summary = os.environ.get("SUMMARY") or ""
          story_slug = os.environ.get("STORY_SLUG") or ""
          chapters_raw = os.environ.get("CHAPTERS") or ""
          content = os.environ.get("CONTENT") or ""
          if not content.strip(): raise SystemExit("Missing content")
          open("work/content.txt","w",encoding="utf-8").write(content.strip()+"\n")

          bg_tt = os.environ.get("BG_TT") or ""
          bg_yt = os.environ.get("BG_YT") or ""
          folder = os.environ.get("FOLDER_NAME") or ""
          voice = os.environ.get("VOICE") or "vi-VN-HoaiMyNeural"
          token = os.environ.get("ACCESS_TOKEN") or ""

          if not summary.strip(): raise SystemExit("Missing summary")
          if not story_slug.strip(): raise SystemExit("Missing storySlug")
          if not chapters_raw.strip(): raise SystemExit("Missing chapters")
          if not bg_tt.strip(): raise SystemExit("Missing background_tiktok_url")
          if not bg_yt.strip(): raise SystemExit("Missing background_youtube_url")
          if not folder.strip(): raise SystemExit("Missing folder_name")
          if not token.strip(): raise SystemExit("Missing access_token")

          # sanitize folder name for Drive subfolder
          folder = re.sub(r'[\/\\:*?"<>|]+', "-", folder.strip())
          folder = re.sub(r"\s+", " ", folder).strip()
          if not folder: raise SystemExit("Invalid folder_name")

          # parse chapters: allow comma/newline/space separated
          parts = re.split(r"[,\n\r\t ]+", chapters_raw.strip())
          chapters = [p.strip() for p in parts if p.strip()]
          if not chapters: raise SystemExit("No valid chapter slugs in chapters")

          # simple slug validation (adjust if your slug allows unicode)
          bad = [c for c in chapters if not re.fullmatch(r"[A-Za-z0-9_-]{1,200}", c)]
          if bad:
            raise SystemExit("Invalid chapter slugs: " + ", ".join(bad))

          open("work/summary.txt","w",encoding="utf-8").write(summary.strip()+"\n")
          open("work/story_slug.txt","w",encoding="utf-8").write(story_slug.strip()+"\n")
          open("work/chapters.txt","w",encoding="utf-8").write("\n".join(chapters) + "\n")
          open("work/bg_tiktok.txt","w",encoding="utf-8").write(bg_tt.strip()+"\n")
          open("work/bg_youtube.txt","w",encoding="utf-8").write(bg_yt.strip()+"\n")
          open("work/folder_name.txt","w",encoding="utf-8").write(folder+"\n")
          open("work/voice.txt","w",encoding="utf-8").write(voice.strip()+"\n")
          open("work/title.txt","w",encoding="utf-8").write(title.strip()+"\n")
          # NEW: intro TTS text
          open("work/intro_tts.txt","w",encoding="utf-8").write("Mời bạn lắng nghe truyện audio cùng Đọc Xíu nhé.\n")
          print(f"OK: chapters={len(chapters)}")
          PY

      - name: Prepare title + upload.txt + encoded text
        run: |
          set -euo pipefail
          DATE="$(date +%Y-%m-%d)"

          python3 - <<'PY'
          import re, urllib.parse
          s=open("work/summary.txt","r",encoding="utf-8").read().strip()
          s=re.sub(r"\s+"," ",s)
          short = (s[:60] + "…") if len(s) > 60 else s
          open("work/summary_oneline.txt","w",encoding="utf-8").write(s+"\n")
          open("work/summary_short.txt","w",encoding="utf-8").write(short+"\n")
          open("work/summary_encoded.txt","w",encoding="utf-8").write(urllib.parse.quote(s, safe="")+"\n")
          PY

          python3 - <<'PY'
          import urllib.parse
          title=open("work/title.txt","r",encoding="utf-8").read().strip()
          open("work/title_encoded.txt","w",encoding="utf-8").write(urllib.parse.quote(title, safe="")+"\n")
          PY

          TITLE="$(cat work/title.txt)"

          cat > work/upload.txt <<EOF
          Title: $TITLE
          Date: $DATE
          Folder: $(cat work/folder_name.txt)
          
          Summary:
          $(cat work/summary_oneline.txt)
          
          StorySlug:
          $(cat work/story_slug.txt)
          
          Chapters:
          $(cat work/chapters.txt)
          EOF

      - name: Create upload.json
        run: |
          set -euo pipefail
          TITLE="$(cat work/title.txt)"
          FOLDER_NAME="$(cat work/folder_name.txt)"
          SUMMARY="$(cat work/summary.txt)"
          CONTENT="$(cat work/content.txt)"

          # Keep json shape compatible with your existing API (remove content_ja)
          jq -n \
            --arg title "$TITLE" \
            --arg description_ja "$SUMMARY" \
            --arg url "/stories/${FOLDER_NAME}" \
            --arg content "$CONTENT" \
            '{
              title: $title,
              description_ja: $description_ja,
              url: $url,
              content: $content
            }' > work/upload_ja.json

      - name: Upload artifact (inputs)
        uses: actions/upload-artifact@v4
        with:
          name: work_inputs
          path: |
            work/summary.txt
            work/story_slug.txt
            work/chapters.txt
            work/bg_tiktok.txt
            work/bg_youtube.txt
            work/folder_name.txt
            work/voice.txt
            work/summary_encoded.txt
            work/title.txt
            work/title_encoded.txt
            work/upload.txt
            work/upload_ja.json
            work/intro_tts.txt
            work/content.txt

  backgrounds:
    name: Download backgrounds
    runs-on: ubuntu-latest
    needs: [prepare]
    steps:
      - uses: actions/download-artifact@v4
        with:
          name: work_inputs
          path: work

      - name: Download backgrounds from Google Drive
        run: |
          set -euo pipefail
          test -n "${ACCESS_TOKEN:-}"

          extract_file_id () {
            python3 - "$1" <<'PY'
          import re, sys
          s=sys.argv[1].strip()
          if re.fullmatch(r"[A-Za-z0-9_-]{10,}", s):
            print(s); sys.exit(0)
          m=re.search(r"/file/d/([A-Za-z0-9_-]+)", s)
          if m: print(m.group(1)); sys.exit(0)
          m=re.search(r"[?&]id=([A-Za-z0-9_-]+)", s)
          if m: print(m.group(1)); sys.exit(0)
          raise SystemExit("Cannot extract drive fileId from: " + s)
          PY
          }

          download_one () {
            SRC="$1"; OUT="$2"
            ID="$(extract_file_id "$SRC")"
            echo "Downloading fileId=$ID -> $OUT"
            curl -fSL --retry 5 --retry-all-errors \
              -H "Authorization: Bearer $ACCESS_TOKEN" \
              "https://www.googleapis.com/drive/v3/files/$ID?alt=media&supportsAllDrives=true" \
              -o "$OUT"
            test -s "$OUT"
          }

          download_one "$(cat work/bg_tiktok.txt)"  work/background_tiktok.jpg
          download_one "$(cat work/bg_youtube.txt)" work/background_youtube.jpg

          ls -lh work/background_*.jpg

      - name: Upload artifact (backgrounds)
        uses: actions/upload-artifact@v4
        with:
          name: work_backgrounds
          path: |
            work/background_tiktok.jpg
            work/background_youtube.jpg

  tts:
    name: Generate TTS from chapters (TikTok + YouTube)
    runs-on: ubuntu-latest
    needs: [prepare]
    steps:
      - uses: actions/download-artifact@v4
        with:
          name: work_inputs
          path: work

      - name: Install ffmpeg + jq + curl
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg jq curl python3

      - name: Fetch chapter contents -> per-chapter TTS mp3 -> concat
        run: |
          set -euo pipefail
          VOICE="$(cat work/voice.txt)"
          
          mkdir -p work/chapters_text work/chapters_audio
          
          # Intro TTS (JP text already in work/intro_tts.txt)
          INTRO_TEXT="$(cat work/intro_tts.txt)"
          
          curl -fSL --retry 5 --retry-all-errors --connect-timeout 10 --max-time 300 \
            -X POST "https://mcp-xiaozhi.vercel.app/api/tts/stream" \
            -H "Content-Type: application/json" \
            -d "$(jq -n --arg text "$INTRO_TEXT" --arg voice "$VOICE" --arg format "mp3" '{text:$text, voice:$voice, format:$format}')" \
            --output "work/chapters_audio/000_intro.mp3"
          
          ffprobe -v error -show_entries format=duration -of default=nw=1:nk=1 \
            "work/chapters_audio/000_intro.mp3" >/dev/null
          
          # Determine N parts from chapters.txt (we only use COUNT, not slugs)
          N="$(grep -v '^[[:space:]]*$' work/chapters.txt | wc -l | tr -d ' ')"
          export N
          test "$N" -ge 1
          echo "Split content into N=$N parts"
          
          # Split content into N chunks (roughly equal by characters, but prefer splitting on paragraph boundaries)
          python3 - <<'PY'
          import os, re, math
          
          content = open("work/content.txt","r",encoding="utf-8").read().strip()
          n = int(os.environ["N"])
          
          # Normalize newlines
          content = content.replace("\r\n","\n").replace("\r","\n").strip()
          
          # Split by paragraphs (blank line separators). If no blank lines, fallback to line-based.
          paras = [p.strip() for p in re.split(r"\n\s*\n+", content) if p.strip()]
          if len(paras) <= 1:
              paras = [ln.strip() for ln in content.split("\n") if ln.strip()]
          
          # Target size by total chars
          total = sum(len(p) for p in paras)
          target = max(1, total // n)
          
          chunks = []
          cur = []
          cur_len = 0
          
          for p in paras:
              # if current chunk already meets target and we still need more chunks, cut here
              if cur and (cur_len >= target) and (len(chunks) < n-1):
                  chunks.append("\n\n".join(cur).strip())
                  cur, cur_len = [], 0
              cur.append(p)
              cur_len += len(p)
          
          if cur:
              chunks.append("\n\n".join(cur).strip())
          
          # If we ended up with fewer chunks than n (e.g. very short content), pad by splitting last chunk
          while len(chunks) < n:
              last = chunks.pop() if chunks else ""
              if len(last) < 50:
                  chunks.append(last)
                  chunks.append("")
              else:
                  mid = len(last)//2
                  # split near nearest newline/space
                  cut = last.rfind("\n", 0, mid)
                  if cut < 0: cut = last.rfind(" ", 0, mid)
                  if cut < 0: cut = mid
                  chunks.append(last[:cut].strip())
                  chunks.append(last[cut:].strip())
          
          # If too many chunks (rare), merge tail
          while len(chunks) > n:
              a = chunks.pop()
              chunks[-1] = (chunks[-1] + "\n\n" + a).strip()
          
          os.makedirs("work/chapters_text", exist_ok=True)
          for i, text in enumerate(chunks, start=1):
              idx = f"{i:03d}"
              open(f"work/chapters_text/{idx}.txt","w",encoding="utf-8").write(text.strip()+"\n")
          
          print("OK chunks:", len(chunks), "total_chars:", total)
          PY
          
          # TTS each part -> mp3
          i=0
          for TXT in work/chapters_text/[0-9][0-9][0-9].txt; do
            i=$((i+1))
            IDX="$(basename "$TXT" .txt)"
            echo "==> TTS part $IDX"
          
            curl -fSL --retry 5 --retry-all-errors --connect-timeout 10 --max-time 300 \
              -X POST "https://mcp-xiaozhi.vercel.app/api/tts/stream" \
              -H "Content-Type: application/json" \
              -d "$(jq -n --arg text "$(cat "$TXT")" --arg voice "$VOICE" --arg format "mp3" '{text:$text, voice:$voice, format:$format}')" \
              --output "work/chapters_audio/${IDX}.mp3"
          
            ffprobe -v error -show_entries format=duration -of default=nw=1:nk=1 \
              "work/chapters_audio/${IDX}.mp3" >/dev/null
          done
          
          test "$i" -ge 1
          
          # TikTok audio = intro + part 1
          ffmpeg -y \
            -i work/chapters_audio/000_intro.mp3 \
            -i work/chapters_audio/001.mp3 \
            -filter_complex "[0:a][1:a]concat=n=2:v=0:a=1" \
            -c:a libmp3lame -b:a 192k \
            work/tts_tiktok.mp3
          
          # YouTube audio = intro + all parts
          rm -f work/concat_list.txt
          echo "file '$(realpath work/chapters_audio/000_intro.mp3)'" >> work/concat_list.txt
          for f in work/chapters_audio/[0-9][0-9][0-9].mp3; do
            echo "file '$(realpath "$f")'" >> work/concat_list.txt
          done
          
          ffmpeg -y -f concat -safe 0 -i work/concat_list.txt \
            -c:a libmp3lame -b:a 192k work/tts_youtube.mp3



      - name: Upload artifact (tts)
        uses: actions/upload-artifact@v4
        with:
          name: work_tts
          path: |
            work/tts_tiktok.mp3
            work/tts_youtube.mp3
            work/concat_list.txt
            work/chapters_text/*.txt

  render:
    name: Render loop videos (chromium)
    runs-on: ubuntu-latest
    needs: [prepare, backgrounds]
    steps:
      - uses: actions/checkout@v4

      - uses: actions/download-artifact@v4
        with:
          name: work_inputs
          path: work

      - uses: actions/download-artifact@v4
        with:
          name: work_backgrounds
          path: work

      - name: Install tools (ffmpeg + chromium + xvfb + fonts)
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            ffmpeg jq curl fontconfig python3 chromium-browser xvfb \
            fonts-noto-core fonts-noto-cjk fonts-noto-cjk-extra
          fc-cache -f -v

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install npm deps (canvas-confetti)
        run: |
          set -euo pipefail
          if [ -f package-lock.json ]; then
            npm ci
          else
            npm install
          fi

      - name: Prepare web assets
        run: |
          set -euo pipefail
          test -s web/scene.html
          cp node_modules/canvas-confetti/dist/confetti.browser.js web/confetti.js

      - name: Record loop videos via chromium --app (separate backgrounds)
        run: |
          set -euo pipefail
          TEXT_ENC="$(cat work/summary_encoded.txt)"
          TITLE_ENC="$(cat work/title_encoded.txt)"

          record_one () {
            MODE="$1"
            if [ "$MODE" = "youtube" ]; then
              W=1920; H=1080
              OUT="work/loop_youtube.mp4"
              cp work/background_youtube.jpg web/background.jpg
            else
              W=1080; H=1920
              OUT="work/loop_tiktok.mp4"
              cp work/background_tiktok.jpg web/background.jpg
            fi

            URL="file://${GITHUB_WORKSPACE}/web/scene.html?w=${W}&h=${H}&mode=${MODE}&text=${TEXT_ENC}&title=${TITLE_ENC}"
            echo "URL=$URL"

            xvfb-run -a -s "-screen 0 1920x1920x24" bash -lc '
              set -euo pipefail
              MODE="'"$MODE"'"
              W="'"$W"'"
              H="'"$H"'"
              OUT="'"$OUT"'"
              URL="'"$URL"'"

              chromium-browser \
                --no-sandbox \
                --disable-setuid-sandbox \
                --disable-dev-shm-usage \
                --disable-gpu \
                --no-first-run \
                --no-default-browser-check \
                --disable-infobars \
                --disable-features=Translate,TranslateUI \
                --lang=ja \
                --app="$URL" \
                --kiosk \
                --window-position=0,0 \
                --window-size=${W},${H} \
                --user-data-dir=/tmp/chrome-${MODE}-$$ \
                >/dev/null 2>&1 &

              CP=$!
              sleep 2

              ffmpeg -y -f x11grab -video_size ${W}x${H} -framerate 30 -i $DISPLAY+0,0 \
                -t 10 -c:v libx264 -pix_fmt yuv420p -preset veryfast -crf 20 "$OUT"

              kill $CP || true
              wait $CP || true
            '

            test -s "$OUT"
            echo "OK: $OUT"
          }

          record_one tiktok
          record_one youtube

      - name: Upload artifact (loops)
        uses: actions/upload-artifact@v4
        with:
          name: work_loops
          path: |
            work/loop_tiktok.mp4
            work/loop_youtube.mp4

  mux:
    name: Mux audio + loop -> final videos
    runs-on: ubuntu-latest
    needs: [tts, render]
    steps:
      - uses: actions/download-artifact@v4
        with:
          name: work_tts
          path: work

      - uses: actions/download-artifact@v4
        with:
          name: work_loops
          path: work

      - name: Install ffmpeg
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg python3

      - name: Loop video to match audio + mux audio (TikTok) [bounded]
        run: |
          set -euo pipefail
          ADUR=$(ffprobe -v error -show_entries format=duration -of default=nw=1:nk=1 work/tts_tiktok.mp3)
          ADUR_CEIL=$(python3 - <<PY
          import math
          print(math.ceil(float("$ADUR")))
          PY
          )

          ffmpeg -y -stream_loop -1 -i work/loop_tiktok.mp4 -i work/tts_tiktok.mp3 \
            -t "$ADUR_CEIL" \
            -c:v libx264 -pix_fmt yuv420p -preset veryfast -crf 20 \
            -c:a aac -b:a 192k -movflags +faststart \
            work/tiktok_ja.mp4

      - name: Loop video to match audio + mux audio (YouTube) [bounded]
        run: |
          set -euo pipefail
          ADUR=$(ffprobe -v error -show_entries format=duration -of default=nw=1:nk=1 work/tts_youtube.mp3)
          ADUR_CEIL=$(python3 - <<PY
          import math
          print(math.ceil(float("$ADUR")))
          PY
          )

          ffmpeg -y -stream_loop -1 -i work/loop_youtube.mp4 -i work/tts_youtube.mp3 \
            -t "$ADUR_CEIL" \
            -c:v libx264 -pix_fmt yuv420p -preset veryfast -crf 20 \
            -c:a aac -b:a 192k -movflags +faststart \
            work/youtube_ja.mp4

      - name: Show output file sizes
        run: |
          set -euo pipefail
          echo "=== File sizes ==="
          ls -lh work/*.mp4 work/*.mp3 || true
          echo
          echo "=== Video duration ==="
          ffprobe -v error -show_entries format=duration -of default=nw=1:nk=1 work/tiktok_ja.mp4
          ffprobe -v error -show_entries format=duration -of default=nw=1:nk=1 work/youtube_ja.mp4

      - name: Upload artifact (final videos)
        uses: actions/upload-artifact@v4
        with:
          name: work_final
          path: |
            work/tiktok_ja.mp4
            work/youtube_ja.mp4

  upload:
    name: Upload to Google Drive
    runs-on: ubuntu-latest
    needs: [prepare, mux]
    steps:
      - uses: actions/download-artifact@v4
        with:
          name: work_inputs
          path: work

      - uses: actions/download-artifact@v4
        with:
          name: work_final
          path: work

      - name: Install tools (curl + jq)
        run: |
          sudo apt-get update
          sudo apt-get install -y curl jq python3

      - name: Upload videos to Google Drive (into subfolder name)
        id: gdrive
        env:
          ROOT_FOLDER_ID: ${{ secrets.GDRIVE_FOLDER_ID }}
        run: |
          set -euo pipefail
          test -n "${ACCESS_TOKEN:-}"
          test -n "${ROOT_FOLDER_ID:-}"

          FOLDER_NAME="$(cat work/folder_name.txt)"
          test -n "${FOLDER_NAME:-}"

          esc_q () {
            python3 - "$1" <<'PY'
          import sys
          s=sys.argv[1]
          s=s.replace("\\","\\\\").replace("'","\\'")
          print(s)
          PY
          }

          urlenc () {
            python3 - "$1" <<'PY'
          import sys, urllib.parse
          print(urllib.parse.quote(sys.argv[1], safe=""))
          PY
          }

          drive_get () {
            curl -sS -D /tmp/drive_headers.txt -o /tmp/drive_body.txt \
              -H "Authorization: Bearer $ACCESS_TOKEN" \
              "$1" || true
            head -n 1 /tmp/drive_headers.txt | awk '{print $2}'
          }

          drive_post_json () {
            curl -sS -D /tmp/drive_headers.txt -o /tmp/drive_body.txt \
              -X POST "$1" \
              -H "Authorization: Bearer $ACCESS_TOKEN" \
              -H "Content-Type: application/json; charset=UTF-8" \
              -d "$2" || true
            head -n 1 /tmp/drive_headers.txt | awk '{print $2}'
          }

          get_or_create_folder () {
            NAME="$1"
            QNAME="$(esc_q "$NAME")"
            Q="mimeType='application/vnd.google-apps.folder' and name='${QNAME}' and '${ROOT_FOLDER_ID}' in parents and trashed=false"

            QENC="$(urlenc "$Q")"
            URL="https://www.googleapis.com/drive/v3/files?q=${QENC}&fields=files(id,name)&pageSize=1&supportsAllDrives=true&includeItemsFromAllDrives=true"

            code="$(drive_get "$URL")"
            if [ "$code" != "200" ]; then
              echo "Drive search folder failed (HTTP $code)"
              cat /tmp/drive_body.txt
              exit 1
            fi

            ID="$(jq -r '.files[0].id // empty' /tmp/drive_body.txt)"
            if [ -n "$ID" ]; then
              echo "$ID"
              return
            fi

            META="$(jq -n --arg name "$NAME" --arg parent "$ROOT_FOLDER_ID" \
              '{name:$name, mimeType:"application/vnd.google-apps.folder", parents:[$parent]}')"

            code="$(drive_post_json "https://www.googleapis.com/drive/v3/files?supportsAllDrives=true" "$META")"
            if [ "$code" != "200" ] && [ "$code" != "201" ]; then
              echo "Drive create folder failed (HTTP $code)"
              cat /tmp/drive_body.txt
              exit 1
            fi

            NEWID="$(jq -r '.id // empty' /tmp/drive_body.txt)"
            test -n "$NEWID"
            echo "$NEWID"
          }

          TARGET_FOLDER_ID="$(get_or_create_folder "$FOLDER_NAME")"
          echo "Target folder id: $TARGET_FOLDER_ID"

          upload_one () {
            FILEPATH="$1"
            OUTKEY="$2"
            MIME="${3:-application/octet-stream}"

            NAME="$(basename "$FILEPATH")"
            FILESIZE="$(stat -c%s "$FILEPATH")"

            META="$(jq -n --arg name "$NAME" --arg folder "$TARGET_FOLDER_ID" '{name:$name, parents:[$folder]}')"

            HEADERS="$(mktemp)"
            BODY="$(mktemp)"
            curl -sS -D "$HEADERS" -o "$BODY" \
              -X POST "https://www.googleapis.com/upload/drive/v3/files?uploadType=resumable&fields=id&supportsAllDrives=true" \
              -H "Authorization: Bearer $ACCESS_TOKEN" \
              -H "Content-Type: application/json; charset=UTF-8" \
              -d "$META" || true

            code="$(head -n 1 "$HEADERS" | awk '{print $2}')"
            if [ "$code" != "200" ] && [ "$code" != "201" ]; then
              echo "Create resumable session failed (HTTP $code)"
              cat "$BODY"
              rm -f "$HEADERS" "$BODY"
              exit 1
            fi

            UPLOAD_URL="$(grep -i '^location:' "$HEADERS" | sed -E 's/^location:\s*//I' | tr -d '\r')"
            rm -f "$HEADERS" "$BODY"
            test -n "$UPLOAD_URL"

            RES_HEADERS="$(mktemp)"
            RES_BODY="$(mktemp)"
            curl -sS -D "$RES_HEADERS" -o "$RES_BODY" \
              -X PUT "$UPLOAD_URL" \
              -H "Authorization: Bearer $ACCESS_TOKEN" \
              -H "Content-Length: $FILESIZE" \
              -H "Content-Type: $MIME" \
              --upload-file "$FILEPATH" || true

            up_code="$(head -n 1 "$RES_HEADERS" | awk '{print $2}')"
            if [ "$up_code" != "200" ] && [ "$up_code" != "201" ]; then
              echo "Upload bytes failed (HTTP $up_code)"
              cat "$RES_BODY"
              rm -f "$RES_HEADERS" "$RES_BODY"
              exit 1
            fi

            FILE_ID="$(jq -r '.id // empty' "$RES_BODY")"
            rm -f "$RES_HEADERS" "$RES_BODY"
            test -n "$FILE_ID"

            curl -sS -X POST "https://www.googleapis.com/drive/v3/files/$FILE_ID/permissions?supportsAllDrives=true" \
              -H "Authorization: Bearer $ACCESS_TOKEN" \
              -H "Content-Type: application/json" \
              -d '{"type":"anyone","role":"reader","allowFileDiscovery":false}' >/dev/null

            INFO="$(curl -sS -H "Authorization: Bearer $ACCESS_TOKEN" \
              "https://www.googleapis.com/drive/v3/files/$FILE_ID?fields=webViewLink,webContentLink&supportsAllDrives=true")"

            VIEW="$(echo "$INFO" | jq -r .webViewLink)"
            DL="$(echo "$INFO" | jq -r .webContentLink)"

            echo "${OUTKEY}_view=$VIEW" >> "$GITHUB_OUTPUT"
            echo "${OUTKEY}_dl=$DL" >> "$GITHUB_OUTPUT"
          }

          upload_one work/tiktok_ja.mp4 tiktok_ja video/mp4
          upload_one work/youtube_ja.mp4 youtube_ja video/mp4
          upload_one work/upload_ja.json meta_ja application/json

      - name: Notify API video_story done
        run: |
          set -euo pipefail
          curl -sS -X POST "https://docxiu.onrender.com/api/workflows/video_story?token=a9f04e7b85c943f48e2cd01ebd4c" \
            -H "Content-Type: application/json" \
            -d "$(jq -n \
              --arg status "done" \
              --arg storyId "$STORY_ID" \
              '{status: $status, storyId: $storyId}')" | jq .

      - name: Upload artifacts (debug bundle)
        uses: actions/upload-artifact@v4
        with:
          name: debug_bundle
          path: |
            work/upload.txt
            work/upload_ja.json
            work/tts_tiktok.mp3
            work/tts_youtube.mp3
            work/loop_tiktok.mp4
            work/loop_youtube.mp4
            work/tiktok_ja.mp4
            work/youtube_ja.mp4
            work/background_tiktok.jpg
            work/background_youtube.jpg
            work/concat_list.txt
            work/chapters_text/*.txt
