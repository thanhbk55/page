name: "Video Backup"

on:
  repository_dispatch:
    types: [tts_dual_text_to_telegram]
  workflow_dispatch:
    inputs:
      summary:
        description: "Summary text (shown on video)"
        required: true
      full:
        description: "Full text (used for TTS audio)"
        required: true
      background_url:
        description: "Background image URL"
        required: true
      voice:
        description: "TTS voice"
        required: false
        default: "vi-VN-HoaiMyNeural"

jobs:
  run:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install tools (ffmpeg + chromium + xvfb)
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg jq curl fonts-noto-core fontconfig python3 chromium-browser xvfb
          chromium-browser --version || true
          ffmpeg -version | head -n 2
          ffprobe -version | head -n 2

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install npm deps (canvas-confetti)
        run: |
          set -euo pipefail
          if [ -f package-lock.json ]; then
            npm ci
          else
            npm install
          fi

      - name: Write inputs to files (safe)
        env:
          SUMMARY_DISPATCH: ${{ github.event.client_payload.summary }}
          FULL_DISPATCH: ${{ github.event.client_payload.full }}
          BG_URL_DISPATCH: ${{ github.event.client_payload.background_url }}
          VOICE_DISPATCH: ${{ github.event.client_payload.voice }}
          SUMMARY_INPUT: ${{ inputs.summary }}
          FULL_INPUT: ${{ inputs.full }}
          BG_URL_INPUT: ${{ inputs.background_url }}
          VOICE_INPUT: ${{ inputs.voice }}
        run: |
          set -euo pipefail
          mkdir -p work
          python3 - <<'PY'
          import os
          summary = os.environ.get("SUMMARY_DISPATCH") or os.environ.get("SUMMARY_INPUT") or ""
          full = os.environ.get("FULL_DISPATCH") or os.environ.get("FULL_INPUT") or ""
          bg_url = os.environ.get("BG_URL_DISPATCH") or os.environ.get("BG_URL_INPUT") or ""
          voice = os.environ.get("VOICE_DISPATCH") or os.environ.get("VOICE_INPUT") or "vi-VN-HoaiMyNeural"
          if not summary.strip(): raise SystemExit("Missing summary")
          if not full.strip(): raise SystemExit("Missing full")
          if not bg_url.strip(): raise SystemExit("Missing background_url")
          open("work/summary.txt","w",encoding="utf-8").write(summary.strip()+"\n")
          open("work/full.txt","w",encoding="utf-8").write(full.strip()+"\n")
          open("work/bg_url.txt","w",encoding="utf-8").write(bg_url.strip()+"\n")
          open("work/voice.txt","w",encoding="utf-8").write(voice.strip()+"\n")
          print("OK")
          PY

      - name: Prepare title + upload.txt + encoded text
        id: prep
        run: |
          set -euo pipefail
          export TZ=Asia/Tokyo
          DATE="$(date +%Y-%m-%d)"
          python3 - <<'PY'
          import re, urllib.parse
          s=open("work/summary.txt","r",encoding="utf-8").read().strip()
          s=re.sub(r"\s+"," ",s)
          short = (s[:60] + "â€¦") if len(s) > 60 else s
          open("work/summary_oneline.txt","w",encoding="utf-8").write(s+"\n")
          open("work/summary_short.txt","w",encoding="utf-8").write(short+"\n")
          open("work/summary_encoded.txt","w",encoding="utf-8").write(urllib.parse.quote(s)+"\n")
          PY
          SUMMARY_ONELINE="$(cat work/summary_oneline.txt)"
          SHORT="$(cat work/summary_short.txt)"
          TITLE="${DATE} ${SHORT}"
          echo "title=$TITLE" >> "$GITHUB_OUTPUT"
          cat > work/upload.txt <<EOF
          Title: $TITLE
          Date: $DATE

          Summary:
          $SUMMARY_ONELINE

          Full text:
          $(cat work/full.txt)
          EOF

      - name: Download background image
        run: |
          set -euo pipefail
          curl -sS -L "$(cat work/bg_url.txt)" --output work/background.jpg
          test -s work/background.jpg

      - name: Generate TTS from full text (mp3)
        run: |
          set -euo pipefail
          VOICE="$(cat work/voice.txt)"
          curl -sS -X POST "https://mcp-xiaozhi.vercel.app/api/tts/stream" \
            -H "Content-Type: application/json" \
            -d "$(jq -n --arg text "$(cat work/full.txt)" --arg voice "$VOICE" --arg format "mp3" '{text:$text, voice:$voice, format:$format}')" \
            --output work/tts.mp3
          test -s work/tts.mp3

      - name: Create web scene (text effects + random confetti presets)
        run: |
          set -euo pipefail
          mkdir -p web
          cp node_modules/canvas-confetti/dist/confetti.browser.js web/confetti.js
          cp work/background.jpg web/background.jpg

          cat > web/scene.html <<'HTML'
          <!doctype html>
          <html translate="no">
          <head>
            <meta charset="utf-8" />
            <meta name="google" content="notranslate">
            <link rel="icon" href="data:,">
            <style>
              html,body { margin:0; background:#000; overflow:hidden; }
              canvas { position:fixed; inset:0; width:100vw; height:100vh; }

              .overlay{
                position:fixed; inset:0;
                display:flex; align-items:center; justify-content:center;
                pointer-events:none;
              }

              /* Mode-driven sizing */
              :root{
                --fontSize: 40px;
                --padY: 20px;
                --padX: 28px;
                --radius: 22px;
                --maxW: 78vw;
                --maxH: 65vh;
                --clampLines: 10;
              }

              .box{
                color:#fff;
                font:600 var(--fontSize) system-ui, -apple-system, "Noto Sans", sans-serif;
                text-align:center;
                line-height:1.35;

                background:rgba(0,0,0,.45);
                padding: var(--padY) var(--padX);
                border-radius: var(--radius);
                max-width: var(--maxW);
                max-height: var(--maxH);

                overflow:hidden;
                display:-webkit-box;
                -webkit-line-clamp: var(--clampLines);
                -webkit-box-orient: vertical;

                text-shadow: 0 2px 10px rgba(0,0,0,.7);
                transform: translateZ(0);
                will-change: transform, filter, opacity;
              }

              /* Random text animations */
              @keyframes popIn {
                0% { transform: scale(.92); opacity:0; filter: blur(2px); }
                100% { transform: scale(1); opacity:1; filter: blur(0); }
              }
              @keyframes floaty {
                0% { transform: translateY(0); }
                50% { transform: translateY(-6px); }
                100% { transform: translateY(0); }
              }
              @keyframes wobble {
                0% { transform: rotate(0deg) scale(1); }
                25% { transform: rotate(-1.5deg) scale(1.01); }
                50% { transform: rotate(1.5deg) scale(1.01); }
                75% { transform: rotate(-1deg) scale(1.005); }
                100% { transform: rotate(0deg) scale(1); }
              }
              @keyframes shimmer {
                0% { filter: brightness(1); }
                50% { filter: brightness(1.15); }
                100% { filter: brightness(1); }
              }
              @keyframes pulse {
                0% { transform: scale(1); }
                50% { transform: scale(1.02); }
                100% { transform: scale(1); }
              }

              .anim-pop { animation: popIn 700ms ease-out both; }
              .anim-float { animation: popIn 700ms ease-out both, floaty 2600ms ease-in-out infinite; }
              .anim-wobble { animation: popIn 700ms ease-out both, wobble 3200ms ease-in-out infinite; }
              .anim-shimmer { animation: popIn 700ms ease-out both, shimmer 2400ms ease-in-out infinite; }
              .anim-pulse { animation: popIn 700ms ease-out both, pulse 2200ms ease-in-out infinite; }
            </style>
          </head>
          <body>
            <canvas id="c"></canvas>
            <div class="overlay"><div class="box" id="t"></div></div>

            <script src="./confetti.js"></script>
            <script>
              const params = new URLSearchParams(location.search);
              const mode = (params.get("mode") || "tiktok").toLowerCase(); // tiktok|youtube
              const W = Number(params.get("w") || 1080);
              const H = Number(params.get("h") || 1920);
              const text = decodeURIComponent(params.get("text") || "");

              // Mode-specific typography (both clamp 4 lines)
              const root = document.documentElement;
              if (mode === "youtube") {
                root.style.setProperty("--fontSize", "42px");
                root.style.setProperty("--padY", "20px");
                root.style.setProperty("--padX", "26px");
                root.style.setProperty("--maxW", "68vw");
                root.style.setProperty("--maxH", "55vh");
                root.style.setProperty("--clampLines", "5");
              } else { // tiktok
                root.style.setProperty("--fontSize", "42px");  // to hÆ¡n
                root.style.setProperty("--padY", "22px");
                root.style.setProperty("--padX", "30px");
                root.style.setProperty("--maxW", "82vw");
                root.style.setProperty("--maxH", "68vh");
                root.style.setProperty("--clampLines", "10");
              }

              const canvas = document.getElementById("c");
              const ctx = canvas.getContext("2d");
              canvas.width = W; canvas.height = H;

              const tEl = document.getElementById("t");
              tEl.textContent = text;

              // Random text animation (changes every few seconds)
              const textAnims = ["anim-pop","anim-float","anim-wobble","anim-shimmer","anim-pulse"];
              function applyRandomTextAnim() {
                for (const a of textAnims) tEl.classList.remove(a);
                const pick = textAnims[Math.floor(Math.random() * textAnims.length)];
                tEl.classList.add(pick);
              }
              applyRandomTextAnim();
              setInterval(applyRandomTextAnim, 4500);

              // Load background
              const bg = new Image();
              bg.src = new URL("./background.jpg", location.href).href;

              function drawBg(){
                const w = canvas.width, h = canvas.height;
                const scale = Math.max(w/bg.width, h/bg.height);
                const sw = bg.width * scale, sh = bg.height * scale;
                const sx = (w - sw)/2, sy = (h - sh)/2;
                ctx.drawImage(bg, sx, sy, sw, sh);
                ctx.fillStyle = "rgba(0,0,0,0.22)";
                ctx.fillRect(0,0,w,h);
              }

              // Confetti helpers
              const rand = (a,b)=> Math.random()*(b-a)+a;
              const pickOne = (arr)=> arr[Math.floor(Math.random()*arr.length)];

              // Support custom shapes / emoji if available
              const emojiList = ["âœ¨","ðŸŽ‰","ðŸ’–","ðŸ”¥","ðŸŒ¸","ðŸ€","â­","ðŸ’¯","ðŸ¥³","ðŸŽŠ","ðŸŒŸ","ðŸŽˆ","ðŸ‹","ðŸ«¶","ðŸ˜º","ðŸ¦Š","ðŸ£"];
              const canShapeFromText = typeof confetti.shapeFromText === "function";
              const canShapeFromPath = typeof confetti.shapeFromPath === "function";

              const emojiShapes = canShapeFromText
                ? emojiList.map(e => confetti.shapeFromText({ text: e, scalar: 1.2 }))
                : null;

              const customShapes = canShapeFromPath ? ([
                confetti.shapeFromPath({ path: "M0 30 L15 0 L30 30 L15 22 Z" }), // diamond-ish
                confetti.shapeFromPath({ path: "M15 0 C23 0 30 7 30 15 C30 23 23 30 15 30 C7 30 0 23 0 15 C0 7 7 0 15 0 Z" }), // circle
                confetti.shapeFromPath({ path: "M15 0 L19 10 L30 10 L21 17 L24 30 L15 22 L6 30 L9 17 L0 10 L11 10 Z" }), // star
                confetti.shapeFromPath({ path: "M0 15 L15 0 L30 15 L15 30 Z" }), // kite
              ]) : null;

              function burst(opts){
                confetti({
                  particleCount: opts.particleCount ?? 120,
                  spread: opts.spread ?? 100,
                  startVelocity: opts.startVelocity ?? 45,
                  ticks: opts.ticks ?? 220,
                  gravity: opts.gravity ?? 0.9,
                  scalar: opts.scalar ?? 1,
                  drift: opts.drift ?? 0,
                  origin: opts.origin ?? { x: 0.5, y: 0.7 },
                  angle: opts.angle,
                  shapes: opts.shapes,
                });
              }

              // Presets
              function presetBasicCannon(){
                burst({
                  particleCount: 140,
                  spread: 70,
                  startVelocity: 55,
                  origin: { x: 0.5, y: 0.95 }
                });
              }

              function presetRandomDirection(){
                const angle = rand(0, 360);
                burst({
                  particleCount: 120,
                  spread: 140,
                  startVelocity: 35,
                  angle,
                  origin: { x: rand(0.15, 0.85), y: rand(0.2, 0.8) }
                });
              }

              function presetRealisticLook(){
                burst({
                  particleCount: 160,
                  spread: 90,
                  startVelocity: 45,
                  gravity: 1.2,
                  scalar: rand(0.8, 1.15),
                  drift: rand(-0.6, 0.6),
                  ticks: 280,
                  origin: { x: rand(0.2, 0.8), y: rand(0.2, 0.6) }
                });
              }

              function presetFireworks(){
                const times = 3;
                for (let i=0;i<times;i++){
                  setTimeout(() => {
                    burst({
                      particleCount: 120,
                      spread: 360,
                      startVelocity: 28,
                      gravity: 0.9,
                      ticks: 260,
                      origin: { x: rand(0.15, 0.85), y: rand(0.15, 0.45) }
                    });
                  }, i * 220);
                }
              }

              function presetStars(){
                // If shapes supported: use star path, else fallback normal
                const shapes = (customShapes && customShapes[2]) ? [customShapes[2]] : undefined;
                burst({
                  particleCount: 120,
                  spread: 110,
                  startVelocity: 38,
                  ticks: 260,
                  scalar: 1.1,
                  gravity: 0.95,
                  shapes,
                  origin: { x: rand(0.2, 0.8), y: rand(0.25, 0.55) }
                });
              }

              function presetSnow(){
                // gentle downward, lots of small particles
                burst({
                  particleCount: 220,
                  spread: 40,
                  startVelocity: 10,
                  gravity: 0.7,
                  ticks: 380,
                  scalar: 0.7,
                  drift: rand(-0.3, 0.3),
                  origin: { x: rand(0.1, 0.9), y: 0.05 },
                  angle: 90
                });
              }

              function presetSchoolPride(){
                // two cannons from left/right bottom (no hardcoded colors)
                burst({ particleCount: 90, spread: 55, startVelocity: 50, origin: { x: 0.1, y: 0.95 }, angle: 60 });
                burst({ particleCount: 90, spread: 55, startVelocity: 50, origin: { x: 0.9, y: 0.95 }, angle: 120 });
              }

              function presetCustomShapes(){
                if (customShapes) {
                  burst({
                    particleCount: 140,
                    spread: 120,
                    startVelocity: 42,
                    ticks: 260,
                    scalar: rand(0.9, 1.2),
                    shapes: [pickOne(customShapes)],
                    origin: { x: rand(0.2, 0.8), y: rand(0.25, 0.6) }
                  });
                } else {
                  presetRealisticLook();
                }
              }

              function presetEmoji(){
                if (emojiShapes) {
                  burst({
                    particleCount: 90,
                    spread: 120,
                    startVelocity: 38,
                    ticks: 280,
                    gravity: 1.0,
                    scalar: rand(0.9, 1.2),
                    shapes: [pickOne(emojiShapes)],
                    origin: { x: rand(0.2, 0.8), y: rand(0.25, 0.55) }
                  });
                } else {
                  presetBasicCannon();
                }
              }

              const presets = [
                { name: "Basic Cannon", fn: presetBasicCannon },
                { name: "Random Direction", fn: presetRandomDirection },
                { name: "Realistic Look", fn: presetRealisticLook },
                { name: "Fireworks", fn: presetFireworks },
                { name: "Stars", fn: presetStars },
                { name: "Snow", fn: presetSnow },
                { name: "School Pride", fn: presetSchoolPride },
                { name: "Custom Shapes", fn: presetCustomShapes },
                { name: "Emoji", fn: presetEmoji },
              ];

              let last = 0;
              function loop(ts){
                drawBg();

                // confetti every ~900ms with random preset
                if (ts - last > 900) {
                  const p = pickOne(presets);
                  p.fn();
                  last = ts;
                }

                requestAnimationFrame(loop);
              }

              bg.onload = () => {
                window.__READY__ = true;
                requestAnimationFrame(loop);
              };
            </script>
          </body>
          </html>
          HTML

      - name: Record loop videos via chromium --app (chromeless) + ffmpeg x11grab
        run: |
          set -euo pipefail
          TEXT_ENC="$(cat work/summary_encoded.txt)"

          record_one () {
            MODE="$1"
            if [ "$MODE" = "youtube" ]; then
              W=1920; H=1080
              OUT="work/loop_youtube.mp4"
            else
              W=1080; H=1920
              OUT="work/loop_tiktok.mp4"
            fi

            URL="file://${GITHUB_WORKSPACE}/web/scene.html?w=${W}&h=${H}&mode=${MODE}&text=${TEXT_ENC}"
            echo "URL=$URL"

            xvfb-run -a -s "-screen 0 1920x1920x24" bash -lc '
              set -euo pipefail
              MODE="'"$MODE"'"
              W="'"$W"'"
              H="'"$H"'"
              OUT="'"$OUT"'"
              URL="'"$URL"'"

              chromium-browser \
                --no-sandbox \
                --disable-setuid-sandbox \
                --disable-dev-shm-usage \
                --disable-gpu \
                --no-first-run \
                --no-default-browser-check \
                --disable-infobars \
                --disable-features=Translate,TranslateUI \
                --lang=vi \
                --app="$URL" \
                --kiosk \
                --window-position=0,0 \
                --window-size=${W},${H} \
                --user-data-dir=/tmp/chrome-${MODE}-$$ \
                >/dev/null 2>&1 &

              CP=$!
              sleep 2

              # Record 10s only (small loop clip)
              ffmpeg -y -f x11grab -video_size ${W}x${H} -framerate 30 -i $DISPLAY+0,0 \
                -t 10 -c:v libx264 -pix_fmt yuv420p -preset veryfast -crf 20 "$OUT"

              kill $CP || true
              wait $CP || true
            '

            test -s "$OUT"
            echo "OK: $OUT"
          }

          record_one tiktok
          record_one youtube

      - name: Loop video to match audio + mux audio (TikTok) [bounded]
        run: |
          set -euo pipefail
          ADUR=$(ffprobe -v error -show_entries format=duration -of default=nw=1:nk=1 work/tts.mp3)
          ADUR_CEIL=$(python3 - <<PY
          import math
          print(math.ceil(float("$ADUR")))
          PY
          )
          ffmpeg -y -stream_loop -1 -i work/loop_tiktok.mp4 -i work/tts.mp3 \
            -t "$ADUR_CEIL" \
            -c:v libx264 -pix_fmt yuv420p -preset veryfast -crf 20 \
            -c:a aac -b:a 192k -movflags +faststart \
            work/tiktok.mp4

      - name: Loop video to match audio + mux audio (YouTube) [bounded]
        run: |
          set -euo pipefail
          ADUR=$(ffprobe -v error -show_entries format=duration -of default=nw=1:nk=1 work/tts.mp3)
          ADUR_CEIL=$(python3 - <<PY
          import math
          print(math.ceil(float("$ADUR")))
          PY
          )
          ffmpeg -y -stream_loop -1 -i work/loop_youtube.mp4 -i work/tts.mp3 \
            -t "$ADUR_CEIL" \
            -c:v libx264 -pix_fmt yuv420p -preset veryfast -crf 20 \
            -c:a aac -b:a 192k -movflags +faststart \
            work/youtube.mp4

      - name: Upload to Telegram
        env:
          TG_BOT_TOKEN: ${{ secrets.TG_BOT_TOKEN }}
          TG_CHAT_ID: ${{ secrets.TG_CHAT_ID }}
          TITLE: ${{ steps.prep.outputs.title }}
        run: |
          set -euo pipefail
          CAPTION="$TITLE"
          curl -sS -X POST "https://api.telegram.org/bot${TG_BOT_TOKEN}/sendVideo" \
            -F chat_id="$TG_CHAT_ID" \
            -F caption="$CAPTION" \
            -F video=@work/tiktok.mp4 | jq .
          curl -sS -X POST "https://api.telegram.org/bot${TG_BOT_TOKEN}/sendVideo" \
            -F chat_id="$TG_CHAT_ID" \
            -F caption="$CAPTION" \
            -F video=@work/youtube.mp4 | jq .
          curl -sS -X POST "https://api.telegram.org/bot${TG_BOT_TOKEN}/sendDocument" \
            -F chat_id="$TG_CHAT_ID" \
            -F caption="$CAPTION" \
            -F document=@work/upload.txt | jq .

      - name: Upload artifacts (optional)
        uses: actions/upload-artifact@v4
        with:
          name: outputs
          path: |
            work/tts.mp3
            work/loop_tiktok.mp4
            work/loop_youtube.mp4
            work/tiktok.mp4
            work/youtube.mp4
            work/upload.txt
